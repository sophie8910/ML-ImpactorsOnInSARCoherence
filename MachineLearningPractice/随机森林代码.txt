#随机森林加叶贝斯算法加特征重要性分析
###步骤一
##基本工具导入
import numpy as np
import pandas as pd
##随机森林模块
from sklearn.ensemble import RandomForestClassifier
import warnings
warnings.filterwarnings('ignore')   #警告过滤器，跳过警告
###步骤二数据导入及处理
weather = pd.read_csv('E:\研究生阶段文件\软件学习\数据集\降雨数据\天气数据.csv')

##用均值来补充缺失值
weather.iloc[:,3:-1]=weather.iloc[:,3:-1].fillna(weather.iloc[:,3:-1].median())

##将所有的列标签变为小写
weather.rename(str.lower,axis='columns',inplace=True)

##创建一个label对象
from sklearn.preprocessing import LabelEncoder
label=LabelEncoder()

##调用Label对象内的fit_transform来将raintomorroww转化成数值型（都转换成int64）
weather["raintomorrow"]=label.fit_transform(weather["raintomorrow"])

##数据划分
x=weather[["humidity9am","humidity3pm","pressure9am","pressure3pm","cloud9am","cloud3pm"]]
y=weather[["raintomorrow"]]
###步骤三划分测试集和训练集
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.65, random_state=1412)
###第四步贝叶斯优化
##贝叶斯的优化器导入（主要有三种这边采用的是bayes_opt)
from bayes_opt import BayesianOptimization
from sklearn.model_selection import cross_val_score
##定义目标函数
def bayesopt_objective(n_estimators, min_samples_split, max_features, max_depth):
    reg = RandomForestClassifier(n_estimators = int(n_estimators)
              ,max_depth = int(max_depth)
              ,max_features = int(max_features)
              ,min_samples_split = int(min_samples_split )
              ,random_state=1412
              ,verbose=False
              ,n_jobs=-1)
    score = cross_val_score(reg, x_train, y_train)
    return score.mean()
##定义参数空间
param_grid_simple = {'n_estimators':(10,200)
                     , 'weights':(1,50)
                     , "max_features":(1,6)
                     , "min_samples_split":(1,50)
                    }
##定义具体的优化流程

def param_bayes_opt(init_points,n_iter):
    opt=BayesianOptimization(bayesopt_objective
                         ,param_grid_simple
                        )
    opt.maximize(init_points=init_points
             ,n_iter=n_iter
             ,random_state=1412
            )
    params_best=opt.max["params"]
    score_best=opt.max["target"]
    print("\n","\n","best params: ",params_best,
      "\n","\n","best score: ", score_best)
    return params_best,score_best
params_best, score_best = param_bayes_opt(10,20) 
###第五步利用最优参数带入随机森林模型
clf1=RandomForestClassifier(max_depth=21,max_features=4,min_samples_split=12,n_estimators=132)
#计算准确率
from sklearn.metrics import accuracy_score
clf1.fit(x_train, y_train)
y_pred = clf1.predict(x_test)
print("随机森林准确率:", accuracy_score(y_test, y_pred))
###第六步特征重要性分析
import eli5
from eli5.sklearn import PermutationImportance
perm = PermutationImportance(clf1,random_state=0).fit(x_test, y_test)
eli5.show_weights(perm, feature_names = x_test.columns.tolist())
##用基尼指数来评价的方法：sklearn已经帮我们封装好了一切，我们只需要调用其中的函数即可
importances = clf1.feature_importances_
feat_labels = weather.columns[3:-1]
indices = np.argsort(importances)[::-1]
for f in range(x_train.shape[1]):
    print("%2d) %-*s %f" % (f + 1, 30, feat_labels[indices[f]], importances[indices[f]]))