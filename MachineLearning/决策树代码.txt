#决策树加贝叶斯加特征重要性分析
###步骤一导入必要的库
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')   #警告过滤器，跳过警告
from sklearn import tree
###步骤二数据导入及处理
weather = pd.read_csv('E:\研究生阶段文件\软件学习\数据集\降雨数据\天气数据.csv')
##用均值来补充缺失值
weather.iloc[:,3:-1]=weather.iloc[:,3:-1].fillna(weather.iloc[:,3:-1].median())

##将所有的列标签变为小写
weather.rename(str.lower,axis='columns',inplace=True)

##创建一个label对象
from sklearn.preprocessing import LabelEncoder
label=LabelEncoder()

##调用Label对象内的fit_transform来将raintomorroww转化成数值型（都转换成int64）
weather["raintomorrow"]=label.fit_transform(weather["raintomorrow"])

##数据划分
x=weather[["humidity9am","humidity3pm","pressure9am","pressure3pm","cloud9am","cloud3pm"]]
y=weather[["raintomorrow"]]
###步骤三划分测试集和训练集
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.65, random_state=1412)
###第四步贝叶斯优化
##贝叶斯的优化器导入（主要有三种这边采用的是bayes_opt)
from bayes_opt import BayesianOptimization
from sklearn.model_selection import cross_val_score
##定义目标函数
def bayesopt_objective( min_samples_split, max_features, max_depth):
    reg = tree.DecisionTreeClassifier(max_depth = int(max_depth)
              ,max_features = int(max_features)
              , min_samples_split = int(min_samples_split )                     
              ,random_state=1412
              ,criterion="gini"
             )
    score = cross_val_score(reg, x_train, y_train)
    return score.mean()
##定义参数空间
param_grid_simple = {'max_depth':(1,50)
                     , "max_features":(1,6)
                     , "min_samples_split":(1,50)
                    }
##定义目标函数的具体流程

def param_bayes_opt(init_points,n_iter):
    opt=BayesianOptimization(bayesopt_objective
                         ,param_grid_simple
                        )
    opt.maximize(init_points=init_points
             ,n_iter=n_iter
             ,random_state=1412
            )
    params_best=opt.max["params"]
    score_best=opt.max["target"]
    print("\n","\n","best params: ",params_best,
      "\n","\n","best score: ", score_best)
    return params_best,score_best
params_best, score_best = param_bayes_opt(5,20) 

###第五步利用最优参数带入决策树模型
clf1=tree.DecisionTreeClassifier(max_depth=49,max_features=5,min_samples_split=38)
#计算准确率
from sklearn.metrics import accuracy_score
clf1.fit(x_train, y_train)
y_pred = clf1.predict(x_test)
print("决策树准确率:", accuracy_score(y_test, y_pred))
##用基尼指数来评价的方法：sklearn已经帮我们封装好了一切，我们只需要调用其中的函数即可
importances = clf1.feature_importances_
feat_labels = weather.columns[3:-1]
indices = np.argsort(importances)[::-1]
for f in range(x_train.shape[1]):
    print("%2d) %-*s %f" % (f + 1, 30, feat_labels[indices[f]], importances[indices[f]]))
feature_name = ["humidity9am","humidity3pm","pressure9am","pressure3pm","cloud9am","cloud3pm"]